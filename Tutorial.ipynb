{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33c8be69-b432-422e-a398-b8016de93584",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Example use case of the  Score-Based Generative Modeling for Conditional Independence Test"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1ee56ef7-c349-4356-9c80-3a1d627f9d32",
   "metadata": {},
   "source": [
    "This notebook provides a simple use case of the Score-Based Generative Modeling for Conditional Independence Test of two variables given we know about other variables that may be related to our quantities of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfa7861-8d58-4846-8043-e2adc8396491",
   "metadata": {},
   "source": [
    "#### What is the Conditional Independence Test?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94a9ee4-6376-4604-86b5-da1c35967528",
   "metadata": {},
   "source": [
    "##### Conditional independence tests are concerned with the question of whether two variables X and Y behave independently of each other, after accounting for the effect of confounders Z. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840924c9-e190-4303-a42c-a55f6fb367a1",
   "metadata": {},
   "source": [
    "##### Let us first generate some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5b9abd2-94ca-4398-9876-990f07a78659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import logging\n",
    "import functools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from dataset.mydataset import mydataset\n",
    "\n",
    "from utils import plot_loss, plot_score\n",
    "from langevin import condition_langevin_dynamics\n",
    "\n",
    "from statistic.rdc import rdc\n",
    "\n",
    "from model.cscore_model import cMLP, cScore\n",
    "from runner.cscore_matching import cscore_matching\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "def generate_multigaussian(n, d):\n",
    "    samples = np.random.multivariate_normal(np.zeros(d),np.eye(d),n)\n",
    "    samples = np.reshape(samples,(n,d))\n",
    "    return samples\n",
    "    \n",
    "def normalize(fX):\n",
    "    fXn = (fX - fX.min())/(fX.max()-fX.min())\n",
    "    return fXn\n",
    "\n",
    "def tranform(x):\n",
    "    return np.log(x)-np.log(1-x)\n",
    "\n",
    "def re_transform(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def same(x):\n",
    "    return x\n",
    "\n",
    "def cube(x):\n",
    "    return np.power(x, 3)\n",
    "\n",
    "def negexp(x):\n",
    "    return np.exp(-np.abs(x))\n",
    "\n",
    "\n",
    "def fselect(I1):\n",
    "    if I1 == 1:\n",
    "        f = same\n",
    "    elif I1 == 2:\n",
    "        f = np.square\n",
    "    elif I1 == 3:\n",
    "        f = np.cos\n",
    "    elif I1 == 4:\n",
    "        f = np.tanh\n",
    "    elif I1 == 5:\n",
    "        f = negexp\n",
    "    return f\n",
    "\n",
    "\n",
    "def plot_gensample(cscore, X_numpy, Z_numpy, eps=0.1, n_steps=100, re_trans=True, return_sample_only = True):\n",
    "    x = torch.randn_like(torch.Tensor(X_numpy)).to(device)\n",
    "    z = torch.Tensor(Z_numpy).to(device)\n",
    "    x0 = condition_langevin_dynamics(cscore, x, z, eps=eps, n_steps=n_steps)\n",
    "    \n",
    "    if not return_sample_only:\n",
    "        fig = plt.figure(figsize = (3,2))\n",
    "        if re_trans:\n",
    "            sns.distplot(re_transform(x0.cpu().numpy()))\n",
    "            sns.distplot(re_transform(X_numpy))\n",
    "        else:\n",
    "            sns.distplot(x0.cpu().numpy())\n",
    "            sns.distplot(X_numpy)       \n",
    "        plt.show()\n",
    "    \n",
    "    if re_trans:\n",
    "        return re_transform(x0.cpu().numpy())\n",
    "    else:\n",
    "        return x0.cpu().numpy()\n",
    "\n",
    "\n",
    "def rdc_permtest(cscore, X_numpy, Y_numpy, Z_numpy, eps=0.1, n_steps=100, B = 100, re_trans=True):\n",
    "    \n",
    "    resample = []\n",
    "    for i in range(B):\n",
    "        x = torch.randn_like(torch.Tensor(X_numpy)).to(device)\n",
    "        z = torch.Tensor(Z_numpy).to(device)\n",
    "        x0 = condition_langevin_dynamics(cscore, x, z, eps=eps, n_steps=n_steps)\n",
    "        resample.append(x0)\n",
    "\n",
    "    rdc_list = []\n",
    "    resample_cpu = torch.cat(resample).detach().cpu().numpy()\n",
    "    l = len(Y_numpy)\n",
    "    for j in range(B):\n",
    "        xp = resample_cpu[l*j:l*(j+1)]\n",
    "        if re_trans:\n",
    "            rdc_list.append(rdc(re_transform(xp), re_transform(Y_numpy))) \n",
    "        else:\n",
    "            rdc_list.append(rdc(xp, Y_numpy)) \n",
    "            \n",
    "    if re_trans:    \n",
    "        rho = rdc(re_transform(X_numpy), re_transform(Y_numpy))\n",
    "    else:\n",
    "        rho = rdc(X_numpy, Y_numpy)\n",
    "        \n",
    "    return rdc_list, rho\n",
    "\n",
    "\n",
    "\n",
    "dx = 1\n",
    "dy = 1\n",
    "dz = 10\n",
    "n = 2000\n",
    "\n",
    "\n",
    "level = 0.0\n",
    "\n",
    "z = generate_multigaussian(n, dz)\n",
    "noise_b = generate_multigaussian(n, dx)\n",
    "y = np.tanh(generate_multigaussian(n, dy)+level*noise_b)\n",
    "x = np.cos(generate_multigaussian(n, dx)+level*noise_b)\n",
    "\n",
    "normal = True\n",
    "if normal:\n",
    "    Z = tranform((normalize(z)+0.01)/1.02)\n",
    "    Y = tranform((normalize(y)+0.01)/1.02)\n",
    "    X = tranform((normalize(x)+0.01)/1.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd4d312-b154-4542-8d40-fd20d6c2c6f6",
   "metadata": {},
   "source": [
    "##### Here we generate X,Y and Z. Next, we split train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20337815-1e15-49a5-9e41-7ab540cd40d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dx,dy,dz (1, 1, 10)\n"
     ]
    }
   ],
   "source": [
    "ratio = int(n//2) # ratio1 = n / 2, ratio2 = n - 1 \n",
    "# ratio = n - 1 \n",
    "\n",
    "Z_train = Z[:ratio]\n",
    "Y_train = Y[:ratio]\n",
    "X_train = X[:ratio]\n",
    "Z_test = Z[ratio:]\n",
    "Y_test = Y[ratio:]\n",
    "X_test = X[ratio:]\n",
    "\n",
    "xz_train = np.concatenate((X_train,Z_train),1)\n",
    "xz_test = np.concatenate((X_test,Z_test),1)\n",
    "xz_train_data = torch.Tensor(xz_train)\n",
    "xz_test_data = torch.Tensor(xz_test)\n",
    "\n",
    "print(\"dx,dy,dz\",(dx,dy,dz)) # shape of x,y and z\n",
    "\n",
    "xz_train_dataset = mydataset(xz_train_data)\n",
    "xz_test_dataset = mydataset(xz_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f3ef56-50ca-420e-acce-3db401f233e9",
   "metadata": {},
   "source": [
    "##### Train our model and output p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b024e089-9044-4d11-ace1-4b35aa5c4821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value 0.4\n"
     ]
    }
   ],
   "source": [
    "net_xz = cMLP(input_dim=dx+dz, output_dim=dx, units = [64,64]).to(device)\n",
    "model_xz = cScore(net_xz).to(device)\n",
    "ScM_xz = cscore_matching(model_xz, device, dx = dx, dz = dz, learning_rate = 1e-4)\n",
    "\n",
    "ScM_xz.load_data(xz_train_dataset, xz_test_dataset, batch_size = 50)\n",
    "ScM_xz.train(epoch=100, debug=0)\n",
    "\n",
    "plot_gensample(ScM_xz.model.score, X_train, Z_train, eps=0.1, n_steps=200, re_trans=True)\n",
    "\n",
    "rdc_l, rho = rdc_permtest(ScM_xz.model.score, X_train, Y_train, Z_train, eps=0.1, n_steps=200, B = 100, re_trans=True)\n",
    "\n",
    "\n",
    "rb = np.array(rdc_l)\n",
    "p_rdc = len(rb[rb>rho])/len(rb)\n",
    "print(\"p-value\", p_rdc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63e1cde-836a-4428-a080-e2ae5f4694a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
